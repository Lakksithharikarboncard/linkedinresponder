async function se(e,t,n){var k,D,O,y,v;if(t.length===0)return{shouldReply:!1,reason:"Empty conversation"};const o=t[t.length-1],s=o.message.toLowerCase(),a=t.filter(i=>i.speaker!==n),r=t.filter(i=>i.speaker===n);if(a.length>0){const i=a[a.length-1],R=i.message.includes("?"),l=r[r.length-1]===o,A=t.findIndex(x=>x===i),p=t.length-1;if(R&&l&&p>A)return{shouldReply:!0,reason:"They answered my question - must acknowledge and continue"}}const d=o.message.split(" ").length<20,u=a.length>0&&r.length>0;if(d&&u&&a.length>=2)return{shouldReply:!0,reason:"Short but engaged response - continuing conversation flow"};if(["not interested","no thanks","not right now","too busy right now","maybe later","not a fit","not looking","thanks but no","appreciate it but","not what we need","have a great day","talk soon","take care","bye","goodbye","gotta go","catch you later"].some(i=>s.includes(i)))return{shouldReply:!1,reason:"Lead explicitly disengaged or ended conversation"};if(["yes","yeah","sure","absolutely","definitely","interested","sounds good","tell me more","how does","what about","can you","could you","would love to","want to know","curious about","?"].some(i=>s.includes(i)))return{shouldReply:!0,reason:"Positive engagement detected - they're interested"};const C=`You are analyzing a LinkedIn conversation to decide if a response is needed.

CONVERSATION (last 20 messages):
${t.slice(-20).map(i=>`${i.speaker}: ${i.message}`).join(`
`)}

CONTEXT: The lead just sent: "${o.message}"

Analyze if you should reply:

REPLY if:
- They asked a question (even indirectly)
- They shared useful information expecting feedback
- They answered YOUR question and conversation should continue
- They showed interest or curiosity
- Natural conversation flow requires acknowledgment

SKIP ONLY if:
- They gave a hard "no" or clear rejection
- They said goodbye and closed the conversation
- They gave a pure acknowledgment with no follow-up needed (like "ok thanks")
- Replying would seem pushy after their closure statement

Respond ONLY with this format:
REPLY: [one sentence reason]
OR
SKIP: [one sentence reason]

Be biased toward REPLY unless there's clear disengagement.`;try{const i=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4o-mini",messages:[{role:"user",content:C}],temperature:.2,max_tokens:60})});if(!i.ok)return{shouldReply:!0,reason:"AI check failed - defaulting to reply"};const l=((y=(O=(D=(k=(await i.json()).choices)==null?void 0:k[0])==null?void 0:D.message)==null?void 0:O.content)==null?void 0:y.trim())||"",A=l.toUpperCase().startsWith("REPLY"),p=((v=l.split(":")[1])==null?void 0:v.trim())||"AI decision";return{shouldReply:A,reason:p}}catch(i){return console.error("‚ùå AI decision check failed:",i),{shouldReply:!0,reason:"AI error - defaulting to engage"}}}async function ae(e,t,n){var s,a,r,d;const o=`You are an AI assistant helping identify qualified leads.
Rule: ${t}
Analyze the following two LinkedIn messages: ${n.join(`
`)}
Respond with only one word: "yes" or "no".`;try{return((d=(r=(a=(s=(await(await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4o-mini",messages:[{role:"user",content:o}],temperature:0,max_tokens:10})})).json()).choices)==null?void 0:s[0])==null?void 0:a.message)==null?void 0:r.content)==null?void 0:d.trim().toLowerCase())==="yes"}catch(u){return console.error("‚ùå GPT lead check failed:",u),!1}}async function ie(e,t,n){const o="re_V2cc9Nqe_2QaLJuLneRiYKEHAnmFGaEc2";try{const s=await fetch("https://api.resend.com/emails",{method:"POST",headers:{Authorization:`Bearer ${o}`,"Content-Type":"application/json"},body:JSON.stringify({from:"LinkedIn AI Bot <onboarding@resend.dev>",to:[n],subject:`üî• Hot Lead: ${e}`,html:`
          <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
            <h1 style="color: #0066cc; border-bottom: 3px solid #0066cc; padding-bottom: 10px;">
              üéØ New Qualified Lead Alert
            </h1>
            
            <div style="background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0;">
              <h2 style="color: #333; margin-top: 0;">Lead Name</h2>
              <p style="font-size: 18px; font-weight: bold; color: #0066cc;">${e}</p>
            </div>

            <div style="background: white; border: 1px solid #ddd; padding: 20px; border-radius: 8px;">
              <h2 style="color: #333;">Conversation History</h2>
              <div style="white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.6; background: #f9f9f9; padding: 15px; border-left: 4px solid #0066cc; overflow-x: auto;">
${t}
              </div>
            </div>

            <div style="margin-top: 30px; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 8px; text-align: center;">
              <h3 style="margin: 0 0 10px 0;">Next Steps</h3>
              <p style="margin: 0; font-size: 14px;">
                Review the conversation and follow up with <strong>${e}</strong> on LinkedIn.
              </p>
            </div>

            <div style="text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #ddd; color: #999; font-size: 12px;">
              <p>Sent by LinkedIn AI Responder</p>
              <p>Automated lead notification system</p>
            </div>
          </div>
        `})});if(!s.ok){const r=await s.json();throw console.error("‚ùå Resend API error:",r),new Error(`Resend API error: ${s.status}`)}const a=await s.json();return console.log("‚úÖ Email sent via Resend:",a),a}catch(s){throw console.error("‚ùå Email send failed:",s),s}}const W="conversation_histories",X=500,re=6e4;function le(e,t){const n=`${e}_${t}`;return btoa(n).substring(0,32)}async function ee(){return new Promise(e=>{chrome.storage.local.get([W],t=>{e(t[W]||{})})})}async function ce(e){return(await ee())[e]||null}async function z(e){const t=await ee();return e.messages.length>X&&(e.messages=e.messages.slice(-X)),t[e.leadId]=e,new Promise(n=>{chrome.storage.local.set({[W]:t},()=>{n()})})}function de(e){return e?Date.now()-e.metadata.lastSyncedAt>re:!0}const j={headline:[".pv-text-details__left-panel h2",".text-body-medium.break-words",'div[data-view-name="profile-headline"]',".pv-top-card--list-bullet .text-body-small"],jobTitle:[".pv-text-details__left-panel .text-body-small:first-of-type",".pv-top-card--list-bullet .text-body-small:first-child"],company:[".pv-text-details__left-panel .text-body-small.inline a",'a[data-field="experience_company_logo"]',".experience-item__company"],location:[".pv-text-details__left-panel .text-body-small:last-of-type","span.text-body-small.inline.t-black--light.break-words",".pv-top-card--list-bullet .text-body-small:last-child"],connectionDegree:[".dist-value","span.dist-value",".pv-top-card--list-bullet span.dist-value"]};function q(e){var t;for(const n of e){const o=document.querySelector(n);if((t=o==null?void 0:o.textContent)!=null&&t.trim())return o.textContent.trim()}return""}function ue(){var t,n;let e=q(j.headline);if(!e){const o=(n=(t=document.querySelector(".msg-thread__link-to-profile"))==null?void 0:t.textContent)==null?void 0:n.trim();o&&(e=o)}return e||"No headline available"}function me(){return q(j.jobTitle)||"Unknown"}function pe(){let e=q(j.company);return e=e.replace(/^at\s+/i,"").trim(),e||"Unknown"}function ge(){return q(j.location)||"Unknown"}function he(){let e=q(j.connectionDegree);const t=e.match(/(\d+(?:st|nd|rd|th))/);return t?t[1]:e||"Unknown"}function fe(){return{headline:ue(),jobTitle:me(),company:pe(),location:ge(),connectionDegree:he(),lastScraped:Date.now()}}function P(e,t){if(!t)return e;const n=[];t.jobTitle&&t.jobTitle!=="Unknown"&&n.push(t.jobTitle),t.company&&t.company!=="Unknown"&&n.push(`@ ${t.company}`),t.location&&t.location!=="Unknown"&&n.push(t.location);const o=n.length>0?` (${n.join(", ")})`:"";return`${e}${o}`}function ye(e){if(!e)return"Profile: Not available";const t=[];return e.headline&&e.headline!=="No headline available"&&t.push(`Headline: ${e.headline}`),e.jobTitle&&e.jobTitle!=="Unknown"&&t.push(`Job Title: ${e.jobTitle}`),e.company&&e.company!=="Unknown"&&t.push(`Company: ${e.company}`),e.location&&e.location!=="Unknown"&&t.push(`Location: ${e.location}`),e.connectionDegree&&e.connectionDegree!=="Unknown"&&t.push(`Connection: ${e.connectionDegree}`),t.join(" | ")}function we(e,t){if(t.messageCount<2)return!1;const n=Math.random()<.2,o=e.split(" ").length>30,s=t.lastMessageQuestions>1;return n||o||s}function be(e,t){const n=[Se,ve,xe,Te];for(const o of n){const s=o(e,t);if(s)return s}return null}function Se(e,t){const n=e.split(/[.!?]/).filter(r=>r.trim());if(n.length<2)return null;const o=Math.floor(n.length/2),s=n.slice(0,o).join(". ").trim(),a=n.slice(o).join(". ").trim();return s.length<10||a.length<5?null:{firstMessage:s,secondMessage:a,delayMs:3e3+Math.random()*4e3,pattern:"price_breakdown"}}function ve(e,t){if(e.split(" ").length<20)return null;const o=e.split(/[.!?]/).filter(u=>u.trim());if(o.length<2)return null;const s=o[0].trim(),a=o.slice(1).join(". ").trim(),r=["Actually, ","Oh and ","Also - "],d=r[Math.floor(Math.random()*r.length)];return{firstMessage:s,secondMessage:d+a.charAt(0).toLowerCase()+a.slice(1),delayMs:5e3+Math.random()*5e3,pattern:"afterthought"}}function xe(e,t){if(!e.includes("?"))return null;const n=["Just ballpark","No pressure","Roughly"];return Math.random()<.3&&e.trim().endsWith("?")?{firstMessage:e.trim(),secondMessage:n[Math.floor(Math.random()*n.length)],delayMs:2e3+Math.random()*2e3,pattern:"question_refinement"}:null}function Te(e,t){if(e.split(" ").length>15||![/^(yeah|yes|yep|sure|sounds good|makes sense|got it|perfect)/i].some(a=>a.test(e)))return null;const s=["üëç","üëå","‚úÖ"];return Math.random()<.4?{firstMessage:e.trim(),secondMessage:s[Math.floor(Math.random()*s.length)],delayMs:1500+Math.random()*2e3,pattern:"emoji_followup"}:null}function Me(e){const n={price_breakdown:3e3,afterthought:6e3,question_refinement:1800,emoji_followup:1500}[e]||3e3,o=n*.4;return n+(Math.random()-.5)*2*o}let I=!1,B=null,E={chatsProcessed:0,repliesSent:0,leadsFound:0,startTime:null,tokensUsed:0,currentModel:""},_=[],J=!0,U=!1,Q="llama-3.3-70b-versatile";function ke(){const e=new Date().getHours(),t=new Date().getDay();return t===0||t===6?"Weekend - keep it casual and light":e<12?"Morning - people are busy, be concise":e<17?"Afternoon - normal business hours":"Evening - they might not respond until tomorrow"}function Ae(e){if(e.length<2)return"First exchange - establish rapport";const t=e[0].timestamp,n=Math.floor((Date.now()-t)/(1e3*60*60*24));return n===0?"New conversation today":n===1?"Ongoing conversation":n>7?"Old conversation - re-engage carefully":`${n}-day conversation`}function Ee(e){const t=e.filter(o=>o.type==="received");if(t.length===0)return"Unknown";const n=t.reduce((o,s)=>o+s.content.split(" ").length,0)/t.length;return n<10?"SHORT replies (5-10 words) - match that brevity":n<25?"MEDIUM replies (10-25 words) - similar length":"LONG replies (25+ words) - you can elaborate more"}function Ce(e){if(!e||!e.jobTitle)return"Professional but friendly";const t=e.jobTitle.toLowerCase();return t.includes("ceo")||t.includes("founder")||t.includes("president")?"EXECUTIVE - Be direct, concise, value-focused. No fluff.":t.includes("director")||t.includes("vp")||t.includes("head")?"SENIOR LEADER - Professional, strategic. Focus on ROI.":t.includes("engineer")||t.includes("developer")?"TECHNICAL - Be specific, mention features. Avoid sales speak.":"PROFESSIONAL - Warm, helpful, consultative."}function c(e,t,n){const o={time:Date.now(),type:e,message:t,actor:n};_.unshift(o),_.length>100&&_.pop(),chrome.storage.local.set({botLog:_.slice(0,50)})}function L(e,t){e==="startTime"?E.startTime=t:e==="tokensUsed"?E.tokensUsed=t:e==="currentModel"?E.currentModel=t:E[e]+=t}function m(e){return new Promise(t=>setTimeout(t,e))}function H(e){return 2e3+e.split(" ").length*300+Math.random()*2e3}function De(e=9,t=18){const n=new Date().getHours();return n>=e&&n<t}async function G(e,t){e.focus(),document.execCommand("selectAll",!1,""),document.execCommand("delete",!1,"");for(const n of t){document.execCommand("insertText",!1,n);const o=Math.random()>.9?150:30+Math.random()*50;await m(o)}}async function Oe(){const e=document.querySelector(".msg-s-message-list-content");if(!e)return;const t=Math.random()*80+20;e.scrollBy(0,t),await m(300+Math.random()*500),e.scrollBy(0,-(Math.random()*50+10)),await m(300+Math.random()*500)}async function Re(e=5){const t=document.querySelector(".msg-conversations-container--inbox-shortcuts");if(t)for(let n=0;n<e;n++)t.scrollBy({top:Math.random()*200+100,behavior:"smooth"}),await m(500+Math.random()*800),t.scrollBy({top:-(Math.random()*50),behavior:"smooth"}),await m(400+Math.random()*500)}async function $e(){return new Promise(e=>{chrome.storage.local.get(["openaiApiKey","groqApiKey","chatMinDelay","chatMaxDelay","loopMinDelay","loopMaxDelay","replyPrompt","leadPrompt","targetEmail","startHour","endHour"],t=>e({apiKey:t.openaiApiKey,groqApiKey:t.groqApiKey||"",chatMin:t.chatMinDelay||1e3,chatMax:t.chatMaxDelay||2500,loopMin:t.loopMinDelay||3e3,loopMax:t.loopMaxDelay||6e3,prompt:t.replyPrompt||"Reply briefly:",leadPrompt:t.leadPrompt||"Interested lead",targetEmail:t.targetEmail||"",startHour:t.startHour||9,endHour:t.endHour||18}))})}function Ie(){var t;const e=document.evaluate('//*[@id="thread-detail-jump-target"]/div/a/div/dl/dt/h2',document,null,XPathResult.FIRST_ORDERED_NODE_TYPE,null).singleNodeValue;return((t=e==null?void 0:e.textContent)==null?void 0:t.trim())||null}function Le(){const e=document.querySelector('a[href*="/in/"]');return(e==null?void 0:e.href)||window.location.href}function Ne(e){var n,o;const t=Array.from(document.querySelectorAll("li.msg-s-message-list__event"));for(let s=t.length-1;s>=0;s--){const a=t[s],r=a.querySelector("span.msg-s-message-group__name"),d=a.querySelector("p.msg-s-event-listitem__body");if(r&&d){const u=((n=r.textContent)==null?void 0:n.trim())||"",g=((o=d.textContent)==null?void 0:o.trim())||"";if(!g)continue;return{fromLead:u.includes(e),content:g}}}return null}async function _e(){const e=document.querySelector(".msg-s-message-list-content");if(!e)return;let t=0,n=e.scrollHeight,o=0;const s=50;for(c("INFO","Loading full conversation history...","System");n>t&&o<s;)t=n,e.scrollTo({top:0,behavior:"smooth"}),await m(800+Math.random()*400),n=e.scrollHeight,o++;c("INFO",`Loaded ${o} message batches`,"System")}async function Pe(e){var o,s;await _e();const t=Array.from(document.querySelectorAll("li.msg-s-message-list__event")),n=[];for(const a of t){const r=a.querySelector("span.msg-s-message-group__name"),d=a.querySelector("p.msg-s-event-listitem__body"),u=a.querySelector("time");if(r&&d){const g=((o=r.textContent)==null?void 0:o.trim())||"Unknown",b=((s=d.textContent)==null?void 0:s.trim())||"";let T=Date.now();if(u){const S=u.getAttribute("datetime");S&&(T=new Date(S).getTime())}const M=g.includes(e)?"received":"sent";b&&n.push({speaker:g,content:b,timestamp:T,type:M})}}return n}async function Ue(e){var u;const t=Le(),n=le(e,t);let o=await ce(n);if(o&&!de(o))return c("INFO",`Using cached data for ${P(e,o.profile)} (${o.messages.length} msgs)`,"System"),o;c("INFO",`Scraping profile for ${e}...`,"System");const s=fe();c("INFO",`Syncing full history for ${e}...`,"System");const a=await Pe(e),r=a[a.length-1],d={leadId:n,leadName:e,profileUrl:t,profile:s,messages:a,metadata:{firstContact:((u=a[0])==null?void 0:u.timestamp)||Date.now(),lastActivity:(r==null?void 0:r.timestamp)||Date.now(),lastMessageFrom:(r==null?void 0:r.type)==="received"?"lead":"me",totalMessages:a.length,lastSyncedAt:Date.now()}};return await z(d),c("SUCCESS",`Saved ${a.length} messages + profile for ${P(e,s)}`,"System"),d}async function je(e,t,n,o,s,a,r=!1,d="llama-3.3-70b-versatile"){var l,A;const u=n.slice(-30),g=u.map(p=>`${p.speaker}: ${p.content}`).join(`
`),b=ke(),T=Ae(n),M=Ee(n),S=Ce(a),k=`You are a real professional messaging on LinkedIn (NOT an AI assistant).
${a?`

LEAD PROFILE:
${ye(a)}
`:""}
TIME CONTEXT: ${b}
CONVERSATION AGE: ${T}
THEIR MESSAGING STYLE: ${M}
TONE ADJUSTMENT: ${S}

CONVERSATION (${n.length} total messages, showing last ${u.length}):
${g}

USER'S INSTRUCTIONS:
${t.replace("{extracted_text}",g).replace("{user_name}",o)}

CRITICAL REALISM RULES:
1. LENGTH: 15-30 words. Real people are busy.
2. TONE: Match their energy. If they write 5 words, you write 7-10.
3. NATURAL: Use contractions (I'm, we're, that's). Be conversational.
4. QUESTIONS: Max ONE follow-up question.
5. AVOID AI PATTERNS:
   - "Thank you for reaching out"
   - "I hope this finds you well"
   - "I'd be happy to..."
   - Corporate jargon
   - Over-enthusiasm (!!!)

Respond as ${s}. Type like you're between meetings.`,D=r?"https://api.groq.com/openai/v1/chat/completions":"https://api.openai.com/v1/chat/completions",O=r?d:"gpt-4o-mini";let y=150;r&&(d==="openai/gpt-oss-120b"?y=500:y=250);const v=await fetch(D,{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:O,messages:[{role:"system",content:k},...u.map(p=>({role:p.type==="received"?"user":"assistant",content:p.content}))],max_tokens:y,temperature:.7})});if(!v.ok)throw new Error(`${r?"Groq":"OpenAI"} API Error`);const i=await v.json(),R=(((l=i.usage)==null?void 0:l.prompt_tokens)||0)+(((A=i.usage)==null?void 0:A.completion_tokens)||0);return{reply:i.choices[0].message.content.trim(),tokensUsed:R}}function qe(){var t;const e=document.querySelector(".global-nav__me-content span");return((t=e==null?void 0:e.textContent)==null?void 0:t.trim())||"You"}function Y(e){return{"openai/gpt-oss-120b":"GPT-OSS-120B","llama-3.3-70b-versatile":"Llama-3.3-70B","meta-llama/llama-4-scout-17b-16e-instruct":"Llama-4-Scout","meta-llama/llama-4-maverick-17b-128e-instruct":"Llama-4-Maverick","moonshotai/kimi-k2-instruct-0905":"Kimi-K2","qwen/qwen3-32b":"Qwen-3-32B","gpt-4o-mini":"GPT-4o-mini","gpt-4o":"GPT-4o"}[e]||e}async function V(e){var D,O;c("INFO",`Starting batch of ${e} chats...`,"System");const{apiKey:t,groqApiKey:n,chatMin:o,chatMax:s,loopMin:a,loopMax:r,prompt:d,leadPrompt:u,targetEmail:g,startHour:b,endHour:T}=await $e(),M=U?n:t,S=U?Q:"gpt-4o-mini";if(L("currentModel",Y(S)),J&&!De(b,T)){c("WARNING",`Outside working hours (${b}-${T}). Pausing.`,"System"),I&&(B=window.setTimeout(()=>V(e),15*60*1e3));return}const C=qe();await Re(5);let k=Array.from(document.querySelectorAll("ul.msg-conversations-container__conversations-list li")).slice(0,e).sort(()=>Math.random()-.2);c("INFO",`Found ${k.length} conversations to check.`,"Bot");for(let y=0;y<k.length&&I;y++){await Oe(),await Z(o,s);const v=k[y].querySelector("a, .msg-conversation-listitem__link, [tabindex='0']");v==null||v.click(),await m(2e3);const i=Ie();if(!i)continue;const R=Ne(i);if(!R||!R.fromLead){c("INFO",`Skipping ${i}: Last message was from me.`,"Bot");continue}const l=await Ue(i);if(c("INFO",`Checking chat with ${P(i,l.profile)}...`,"Bot"),L("chatsProcessed",1),l.messages.length===0){c("WARNING",`No messages found for ${i}`,"System");continue}const A=l.messages.slice(-8).map(h=>({speaker:h.speaker,message:h.content}));let p;try{p=await se(M,A,i),c("ACTION",`AI Decision for ${i}: ${p.shouldReply?"REPLY":"SKIP"} (${p.reason})`,"Bot")}catch(h){c("ERROR",`AI Decision Failed: ${K(h)}`,"System");continue}if(!p.shouldReply)continue;if(g)try{const h=l.messages.slice(-2).map(f=>f.content);if(await ae(M,u,h)){const f=l.messages.map($=>`${$.speaker}: ${$.content}`).join(`
`);await ie(i,f,g),L("leadsFound",1),c("SUCCESS",`HOT LEAD FOUND: ${i}. Email sent!`,"Bot")}}catch(h){c("ERROR",`Lead check failed: ${K(h)}`,"System")}let x;try{x=await je(M,d,l.messages,i,C,l.profile,U,Q),L("tokensUsed",E.tokensUsed+x.tokensUsed)}catch(h){c("ERROR",`Reply Generation Failed: ${K(h)}`,"System");continue}const N=document.querySelector("div.msg-form__contenteditable[role='textbox']"),w=document.querySelector("button.msg-form__send-button");if(N&&w){const h={messageCount:l.messages.length,lastMessageQuestions:(((D=l.messages[l.messages.length-1])==null?void 0:D.content.match(/\?/g))||[]).length},f=we(x.reply,h)?be(x.reply,h):null;if(f){c("ACTION",`Double-texting ${i} (${f.pattern})...`,"Bot");const $=H(f.firstMessage);if(await m($),await G(N,f.firstMessage),await m(800),!(w.hasAttribute("disabled")||w.classList.contains("disabled"))){w.click(),await m(500);const F=Me(f.pattern);c("INFO",`Waiting ${Math.round(F/1e3)}s before second message...`,"Bot"),await m(F);const oe=H(f.secondMessage);await m(oe),await G(N,f.secondMessage),await m(800),w.hasAttribute("disabled")||w.classList.contains("disabled")||(w.click(),await m(500),L("repliesSent",1),l.messages.push({speaker:C,content:f.firstMessage,timestamp:Date.now()-F,type:"sent"},{speaker:C,content:f.secondMessage,timestamp:Date.now(),type:"sent"}),l.metadata.lastActivity=Date.now(),l.metadata.lastMessageFrom="me",l.metadata.totalMessages+=2,l.metadata.lastSyncedAt=Date.now(),await z(l),c("SUCCESS",`Double-texted ${P(i,l.profile)} (${Y(S)}) [History: ${l.messages.length} msgs]`,"Bot"))}}else{const $=H(x.reply);c("ACTION",`Typing reply to ${i} (waiting ${Math.round($/1e3)}s)...`,"Bot"),await m($),await G(N,x.reply),await m(800),w.hasAttribute("disabled")||w.classList.contains("disabled")?c("ERROR",`Send button disabled for ${i}`,"System"):(w.click(),await m(500),(((O=N.textContent)==null?void 0:O.trim())||"").length===0?(L("repliesSent",1),l.messages.push({speaker:C,content:x.reply,timestamp:Date.now(),type:"sent"}),l.metadata.lastActivity=Date.now(),l.metadata.lastMessageFrom="me",l.metadata.totalMessages++,l.metadata.lastSyncedAt=Date.now(),await z(l),c("SUCCESS",`Sent reply to ${P(i,l.profile)} (${Y(S)}) [History: ${l.messages.length} msgs]`,"Bot")):c("WARNING",`Message may not have sent to ${i}`,"System"))}}else c("ERROR","Could not find chat input box","System");await Z(o,s)}c("INFO","Batch finished. Sleeping...","System"),I&&(B=window.setTimeout(()=>V(e),Math.floor(Math.random()*(r-a+1))+a))}function Z(e,t){return m(Math.floor(Math.random()*(t-e+1))+e)}function K(e){return typeof e=="string"?e:e&&typeof e=="object"&&"message"in e?e.message:"Unknown error"}chrome.runtime.onMessage.addListener((e,t,n)=>{var o,s,a,r;if(e.type==="PING_TEST"){n("‚úÖ Content script active!");return}if(e.type==="GET_STATUS"){n({running:I,stats:E,logs:_});return}if(e.type==="START_BOT"){I?n({status:"error",error:"Already running"}):(I=!0,E.startTime=Date.now(),E.tokensUsed=0,J=((o=e.config)==null?void 0:o.strictHours)??!0,U=((s=e.config)==null?void 0:s.useGroq)??!1,Q=((a=e.config)==null?void 0:a.groqModel)??"llama-3.3-70b-versatile",c("INFO",`Bot started (Provider: ${U?"Groq":"OpenAI"}, Strict Hours: ${J?"ON":"OFF"})`,"User"),V(((r=e.config)==null?void 0:r.nChats)??10),n({status:"ok"}));return}if(e.type==="STOP_BOT"){I=!1,B!==null&&clearTimeout(B),c("INFO","Bot stopped by user","User"),n({status:"stopped"});return}});
