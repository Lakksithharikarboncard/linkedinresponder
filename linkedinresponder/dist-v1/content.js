(function(){"use strict";const y={openaiApiKey:"openaiApiKey",groqApiKey:"groqApiKey",resendApiKey:"resendApiKey",replyPrompt:"replyPrompt",leadPrompt:"leadPrompt",targetEmail:"targetEmail",chatMinDelay:"chatMinDelay",chatMaxDelay:"chatMaxDelay",loopMinDelay:"loopMinDelay",loopMaxDelay:"loopMaxDelay",startHour:"startHour",endHour:"endHour"},w={openaiApiKey:"",groqApiKey:"",resendApiKey:"",replyPrompt:`You are {user_name}'s assistant. Reply to this lead based on context:
{extracted_text}
Reply briefly and professionally.`,leadPrompt:"Does this conversation indicate strong buying intent or interest? Reply YES or NO.",targetEmail:"",chatMinDelay:2e3,chatMaxDelay:5e3,loopMinDelay:1e4,loopMaxDelay:3e4,startHour:9,endHour:18};function le(e,t,n,o){const s=typeof e=="number"?e:Number(e);if(!Number.isFinite(s))return o;const a=Math.round(s);return Math.min(n,Math.max(t,a))}function Y(e,t,n,o){const s=typeof e=="number"?e:Number(e);return Number.isFinite(s)?Math.min(n,Math.max(t,Math.floor(s))):o}function P(e,t){return typeof e!="string"?t:e}function pe(e){return e.trim()}function nt(e){return e}async function ce(){return new Promise(e=>{chrome.storage.local.get(Object.values(y),t=>{const n=Y(t[y.chatMinDelay],250,6e4,w.chatMinDelay),o=Y(t[y.chatMaxDelay],250,12e4,w.chatMaxDelay),s=Y(t[y.loopMinDelay],500,6e5,w.loopMinDelay),a=Y(t[y.loopMaxDelay],500,6e5,w.loopMaxDelay),r=Math.min(n,o),c=Math.max(n,o),m=Math.min(s,a),g=Math.max(s,a),S=le(t[y.startHour],0,23,w.startHour),T=le(t[y.endHour],0,23,w.endHour),A={openaiApiKey:P(t[y.openaiApiKey],w.openaiApiKey).trim(),groqApiKey:P(t[y.groqApiKey],w.groqApiKey).trim(),resendApiKey:P(t[y.resendApiKey],w.resendApiKey).trim(),replyPrompt:P(t[y.replyPrompt],w.replyPrompt),leadPrompt:P(t[y.leadPrompt],w.leadPrompt),targetEmail:pe(P(t[y.targetEmail],w.targetEmail)),chatMinDelay:r,chatMaxDelay:c,loopMinDelay:m,loopMaxDelay:g,startHour:S,endHour:T};e(A)})})}async function ge(e,t,n){var O,N,I,k,R;if(t.length===0)return{shouldReply:!1,reason:"Empty conversation"};const o=t[t.length-1],s=o.message.toLowerCase(),a=t.filter(u=>u.speaker!==n),r=t.filter(u=>u.speaker===n);if(a.length>0){const u=a[a.length-1],d=u.message.includes("?"),D=r[r.length-1]===o,l=t.findIndex(_=>_===u),x=t.length-1;if(d&&D&&x>l)return{shouldReply:!0,reason:"They answered my question - must acknowledge and continue"}}const c=o.message.split(" ").length<20,m=a.length>0&&r.length>0;if(c&&m&&a.length>=2)return{shouldReply:!0,reason:"Short but engaged response - continuing conversation flow"};if(["not interested","no thanks","not right now","too busy right now","maybe later","not a fit","not looking","thanks but no","appreciate it but","not what we need","have a great day","talk soon","take care","bye","goodbye","gotta go","catch you later"].some(u=>s.includes(u)))return{shouldReply:!1,reason:"Lead explicitly disengaged or ended conversation"};if(["yes","yeah","sure","absolutely","definitely","interested","sounds good","tell me more","how does","what about","can you","could you","would love to","want to know","curious about","?"].some(u=>s.includes(u)))return{shouldReply:!0,reason:"Positive engagement detected - they're interested"};const ie=`You are analyzing a LinkedIn conversation to decide if a response is needed.

CONVERSATION (last 20 messages):
${t.slice(-20).map(u=>`${u.speaker}: ${u.message}`).join(`
`)}

CONTEXT: The lead just sent: "${o.message}"

Analyze if you should reply:

REPLY if:
- They asked a question (even indirectly)
- They shared useful information expecting feedback
- They answered YOUR question and conversation should continue
- They showed interest or curiosity
- Natural conversation flow requires acknowledgment

SKIP ONLY if:
- They gave a hard "no" or clear rejection
- They said goodbye and closed the conversation
- They gave a pure acknowledgment with no follow-up needed (like "ok thanks")
- Replying would seem pushy after their closure statement

Respond ONLY with this format:
REPLY: [one sentence reason]
OR
SKIP: [one sentence reason]

Be biased toward REPLY unless there's clear disengagement.`;try{const u=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4o-mini",messages:[{role:"user",content:ie}],temperature:.2,max_tokens:60})});if(!u.ok)return{shouldReply:!0,reason:"AI check failed - defaulting to reply"};const D=((k=(I=(N=(O=(await u.json()).choices)==null?void 0:O[0])==null?void 0:N.message)==null?void 0:I.content)==null?void 0:k.trim())||"",l=D.toUpperCase().startsWith("REPLY"),x=((R=D.split(":")[1])==null?void 0:R.trim())||"AI decision";return{shouldReply:l,reason:x}}catch(u){return console.error("‚ùå AI decision check failed:",u),{shouldReply:!0,reason:"AI error - defaulting to engage"}}}async function he(e,t,n){var s,a,r,c;const o=`You are an AI assistant helping identify qualified leads.
Rule: ${t}
Analyze the following two LinkedIn messages: ${n.join(`
`)}
Respond with only one word: "yes" or "no".`;try{return((c=(r=(a=(s=(await(await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:"gpt-4o-mini",messages:[{role:"user",content:o}],temperature:0,max_tokens:10})})).json()).choices)==null?void 0:s[0])==null?void 0:a.message)==null?void 0:r.content)==null?void 0:c.trim().toLowerCase())==="yes"}catch(m){return console.error("‚ùå GPT lead check failed:",m),!1}}async function ye(e,t,n){const{resendApiKey:o}=await ce();if(!o||o.trim().length===0)throw new Error("Resend API key is not set in Options. Please configure resendApiKey.");const s=await fetch("https://api.resend.com/emails",{method:"POST",headers:{Authorization:`Bearer ${o}`,"Content-Type":"application/json"},body:JSON.stringify({from:"LinkedIn AI Bot <onboarding@resend.dev>",to:[n],subject:`üî• Hot Lead: ${e}`,html:`
        <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
          <h1 style="color: #0066cc; border-bottom: 3px solid #0066cc; padding-bottom: 10px;">
            üéØ New Qualified Lead Alert
          </h1>

          <div style="background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0;">
            <h2 style="color: #333; margin-top: 0;">Lead Name</h2>
            <p style="font-size: 18px; font-weight: bold; color: #0066cc;">${e}</p>
          </div>

          <div style="background: white; border: 1px solid #ddd; padding: 20px; border-radius: 8px;">
            <h2 style="color: #333;">Conversation History</h2>
            <div style="white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 14px; line-height: 1.6; background: #f9f9f9; padding: 15px; border-left: 4px solid #0066cc; overflow-x: auto;">
${t}
            </div>
          </div>

          <div style="margin-top: 30px; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 8px; text-align: center;">
            <h3 style="margin: 0 0 10px 0;">Next Steps</h3>
            <p style="margin: 0; font-size: 14px;">
              Review the conversation and follow up with <strong>${e}</strong> on LinkedIn.
            </p>
          </div>

          <div style="text-align: center; margin-top: 30px; padding-top: 20px; border-top: 1px solid #ddd; color: #999; font-size: 12px;">
            <p>Sent by LinkedIn AI Responder</p>
            <p>Automated lead notification system</p>
          </div>
        </div>
      `})});if(!s.ok){const r=await s.json().catch(()=>null);throw console.error("‚ùå Resend API error:",r),new Error(`Resend API error: ${s.status}`)}const a=await s.json();return console.log("‚úÖ Email sent via Resend:",a),a}const V="conversation_histories",ue=500,fe=6e4;function we(e,t){const n=`${e}_${t}`;return btoa(unescape(encodeURIComponent(n))).substring(0,32)}async function de(){return new Promise(e=>{chrome.storage.local.get([V],t=>{e(t[V]||{})})})}async function be(e){return(await de())[e]||null}async function Q(e){const t=await de();return e.messages.length>ue&&(e.messages=e.messages.slice(-ue)),t[e.leadId]=e,new Promise(n=>{chrome.storage.local.set({[V]:t},()=>{n()})})}function Me(e){return e?Date.now()-e.metadata.lastSyncedAt>fe:!0}const F={headline:[".pv-text-details__left-panel h2",".text-body-medium.break-words",'div[data-view-name="profile-headline"]',".pv-top-card--list-bullet .text-body-small"],jobTitle:[".pv-text-details__left-panel .text-body-small:first-of-type",".pv-top-card--list-bullet .text-body-small:first-child"],company:[".pv-text-details__left-panel .text-body-small.inline a",'a[data-field="experience_company_logo"]',".experience-item__company"],location:[".pv-text-details__left-panel .text-body-small:last-of-type","span.text-body-small.inline.t-black--light.break-words",".pv-top-card--list-bullet .text-body-small:last-child"],connectionDegree:[".dist-value","span.dist-value",".pv-top-card--list-bullet span.dist-value"]};function j(e){var t;for(const n of e){const o=document.querySelector(n);if((t=o==null?void 0:o.textContent)!=null&&t.trim())return o.textContent.trim()}return""}function Se(){var t,n;let e=j(F.headline);if(!e){const o=(n=(t=document.querySelector(".msg-thread__link-to-profile"))==null?void 0:t.textContent)==null?void 0:n.trim();o&&(e=o)}return e||"No headline available"}function xe(){return j(F.jobTitle)||"Unknown"}function ve(){let e=j(F.company);return e=e.replace(/^at\s+/i,"").trim(),e||"Unknown"}function Te(){return j(F.location)||"Unknown"}function Ae(){let e=j(F.connectionDegree);const t=e.match(/(\d+(?:st|nd|rd|th))/);return t?t[1]:e||"Unknown"}function ke(){return{headline:Se(),jobTitle:xe(),company:ve(),location:Te(),connectionDegree:Ae(),lastScraped:Date.now()}}function B(e,t){if(!t)return e;const n=[];t.jobTitle&&t.jobTitle!=="Unknown"&&n.push(t.jobTitle),t.company&&t.company!=="Unknown"&&n.push(`@ ${t.company}`),t.location&&t.location!=="Unknown"&&n.push(t.location);const o=n.length>0?` (${n.join(", ")})`:"";return`${e}${o}`}function De(e){if(!e)return"Profile: Not available";const t=[];return e.headline&&e.headline!=="No headline available"&&t.push(`Headline: ${e.headline}`),e.jobTitle&&e.jobTitle!=="Unknown"&&t.push(`Job Title: ${e.jobTitle}`),e.company&&e.company!=="Unknown"&&t.push(`Company: ${e.company}`),e.location&&e.location!=="Unknown"&&t.push(`Location: ${e.location}`),e.connectionDegree&&e.connectionDegree!=="Unknown"&&t.push(`Connection: ${e.connectionDegree}`),t.join(" | ")}function Ee(e,t){if(t.messageCount<2)return!1;const n=Math.random()<.2,o=e.split(" ").length>30,s=t.lastMessageQuestions>1;return n||o||s}function Ce(e,t){const n=[Oe,Re,Ne,Ie];for(const o of n){const s=o(e,t);if(s)return s}return null}function Oe(e,t){const n=e.split(/[.!?]/).filter(r=>r.trim());if(n.length<2)return null;const o=Math.floor(n.length/2),s=n.slice(0,o).join(". ").trim(),a=n.slice(o).join(". ").trim();return s.length<10||a.length<5?null:{firstMessage:s,secondMessage:a,delayMs:3e3+Math.random()*4e3,pattern:"price_breakdown"}}function Re(e,t){if(e.split(" ").length<20)return null;const o=e.split(/[.!?]/).filter(m=>m.trim());if(o.length<2)return null;const s=o[0].trim(),a=o.slice(1).join(". ").trim(),r=["Actually, ","Oh and ","Also - "],c=r[Math.floor(Math.random()*r.length)];return{firstMessage:s,secondMessage:c+a.charAt(0).toLowerCase()+a.slice(1),delayMs:5e3+Math.random()*5e3,pattern:"afterthought"}}function Ne(e,t){if(!e.includes("?"))return null;const n=["Just ballpark","No pressure","Roughly"];return Math.random()<.3&&e.trim().endsWith("?")?{firstMessage:e.trim(),secondMessage:n[Math.floor(Math.random()*n.length)],delayMs:2e3+Math.random()*2e3,pattern:"question_refinement"}:null}function Ie(e,t){if(e.split(" ").length>15||![/^(yeah|yes|yep|sure|sounds good|makes sense|got it|perfect)/i].some(a=>a.test(e)))return null;const s=["üëç","üëå","‚úÖ"];return Math.random()<.4?{firstMessage:e.trim(),secondMessage:s[Math.floor(Math.random()*s.length)],delayMs:1500+Math.random()*2e3,pattern:"emoji_followup"}:null}function $e(e){const n={price_breakdown:3e3,afterthought:6e3,question_refinement:1800,emoji_followup:1500}[e]||3e3,o=n*.4;return n+(Math.random()-.5)*2*o}let b=!1,M=!1,W=null,H={chatsProcessed:0,repliesSent:0,leadsFound:0,startTime:null,tokensUsed:0,currentModel:""},q=[],X=!0,K=!1,Z="llama-3.3-70b-versatile",ee=!1,v=null,te=[];function Pe(){const e=new Date().getHours(),t=new Date().getDay();return t===0||t===6?"Weekend - keep it casual and light":e<12?"Morning - people are busy, be concise":e<17?"Afternoon - normal business hours":"Evening - they might not respond until tomorrow"}function Le(e){if(e.length<2)return"First exchange - establish rapport";const t=e[0].timestamp,n=Math.floor((Date.now()-t)/(1e3*60*60*24));return n===0?"New conversation today":n===1?"Ongoing conversation":n>7?"Old conversation - re-engage carefully":`${n}-day conversation`}function _e(e){const t=e.filter(o=>o.type==="received");if(t.length===0)return"Unknown";const n=t.reduce((o,s)=>o+s.content.split(" ").length,0)/t.length;return n<10?"SHORT replies (5-10 words) - match that brevity":n<25?"MEDIUM replies (10-25 words) - similar length":"LONG replies (25+ words) - you can elaborate more"}function Ue(e){if(!e||!e.jobTitle)return"Professional but friendly";const t=e.jobTitle.toLowerCase();return t.includes("ceo")||t.includes("founder")||t.includes("president")?"EXECUTIVE - Be direct, concise, value-focused. No fluff.":t.includes("director")||t.includes("vp")||t.includes("head")?"SENIOR LEADER - Professional, strategic. Focus on ROI.":t.includes("engineer")||t.includes("developer")?"TECHNICAL - Be specific, mention features. Avoid sales speak.":"PROFESSIONAL - Warm, helpful, consultative."}function i(e,t,n){const o={time:Date.now(),type:e,message:t,actor:n};q.unshift(o),q.length>100&&q.pop(),chrome.storage.local.set({botLog:q.slice(0,50)})}function L(e,t){e==="startTime"?H.startTime=t:e==="currentModel"?H.currentModel=t:H[e]+=t}function p(e){return new Promise(t=>setTimeout(t,e))}function ne(e){return 2e3+e.split(" ").length*300+Math.random()*2e3}function Fe(e=9,t=18){const n=new Date().getHours();return n>=e&&n<t}async function oe(e,t){e.focus(),document.execCommand("selectAll",!1,""),document.execCommand("delete",!1,"");for(const n of t){document.execCommand("insertText",!1,n);const o=Math.random()>.9?150:30+Math.random()*50;await p(o)}}async function je(){const e=document.querySelector(".msg-s-message-list-content");if(!e)return;const t=Math.random()*80+20;e.scrollBy(0,t),await p(300+Math.random()*500),e.scrollBy(0,-(Math.random()*50+10)),await p(300+Math.random()*500)}async function Be(e=5){const t=document.querySelector(".msg-conversations-container--inbox-shortcuts");if(t)for(let n=0;n<e;n++)t.scrollBy({top:Math.random()*200+100,behavior:"smooth"}),await p(500+Math.random()*800),t.scrollBy({top:-(Math.random()*50),behavior:"smooth"}),await p(400+Math.random()*500)}async function He(){const e=await ce();return{apiKey:e.openaiApiKey,groqApiKey:e.groqApiKey,chatMin:e.chatMinDelay,chatMax:e.chatMaxDelay,loopMin:e.loopMinDelay,loopMax:e.loopMaxDelay,prompt:e.replyPrompt,leadPrompt:e.leadPrompt,targetEmail:e.targetEmail,startHour:e.startHour,endHour:e.endHour}}function qe(){var t;const e=document.evaluate('//*[@id="thread-detail-jump-target"]/div/a/div/dl/dt/h2',document,null,XPathResult.FIRST_ORDERED_NODE_TYPE,null).singleNodeValue;return((t=e==null?void 0:e.textContent)==null?void 0:t.trim())||null}function Ke(){const e=document.querySelector('a[href*="/in/"]');return(e==null?void 0:e.href)||window.location.href}function Ge(e){var n,o;const t=Array.from(document.querySelectorAll("li.msg-s-message-list__event"));for(let s=t.length-1;s>=0;s--){const a=t[s],r=a.querySelector("span.msg-s-message-group__name"),c=a.querySelector("p.msg-s-event-listitem__body");if(r&&c){const m=((n=r.textContent)==null?void 0:n.trim())||"",g=((o=c.textContent)==null?void 0:o.trim())||"";if(!g)continue;return{fromLead:m.includes(e),content:g}}}return null}async function Ye(){const e=document.querySelector(".msg-s-message-list-content");if(!e)return;let t=0,n=e.scrollHeight,o=0;const s=50;for(i("INFO","Loading full conversation history...","System");n>t&&o<s;)t=n,e.scrollTo({top:0,behavior:"smooth"}),await p(800+Math.random()*400),n=e.scrollHeight,o++;i("INFO",`Loaded ${o} message batches`,"System")}async function We(e){var o,s;await Ye();const t=Array.from(document.querySelectorAll("li.msg-s-message-list__event")),n=[];for(const a of t){const r=a.querySelector("span.msg-s-message-group__name"),c=a.querySelector("p.msg-s-event-listitem__body"),m=a.querySelector("time");if(r&&c){const g=((o=r.textContent)==null?void 0:o.trim())||"Unknown",S=((s=c.textContent)==null?void 0:s.trim())||"";let T=Date.now();if(m){const C=m.getAttribute("datetime");C&&(T=new Date(C).getTime())}const A=g.includes(e)?"received":"sent";S&&n.push({speaker:g,content:S,timestamp:T,type:A})}}return n}async function ze(e){var m;const t=Ke(),n=we(e,t);let o=await be(n);if(o&&!Me(o))return i("INFO",`Using cached data for ${B(e,o.profile)} (${o.messages.length} msgs)`,"System"),o;i("INFO",`Scraping profile for ${e}...`,"System");const s=ke();i("INFO",`Syncing full history for ${e}...`,"System");const a=await We(e),r=a[a.length-1],c={leadId:n,leadName:e,profileUrl:t,profile:s,messages:a,metadata:{firstContact:((m=a[0])==null?void 0:m.timestamp)||Date.now(),lastActivity:(r==null?void 0:r.timestamp)||Date.now(),lastMessageFrom:(r==null?void 0:r.type)==="received"?"lead":"me",totalMessages:a.length,lastSyncedAt:Date.now()}};return await Q(c),i("SUCCESS",`Saved ${a.length} messages + profile for ${B(e,s)}`,"System"),c}async function Je(e,t,n,o,s,a,r=!1,c="llama-3.3-70b-versatile"){var D,l;const m=n.slice(-30),g=m.map(x=>`${x.speaker}: ${x.content}`).join(`
`),S=Pe(),T=Le(n),A=_e(n),C=Ue(a),O=`You are a real professional messaging on LinkedIn (NOT an AI assistant).
${a?`

LEAD PROFILE:
${De(a)}
`:""}
TIME CONTEXT: ${S}
CONVERSATION AGE: ${T}
THEIR MESSAGING STYLE: ${A}
TONE ADJUSTMENT: ${C}

CONVERSATION (${n.length} total messages, showing last ${m.length}):
${g}

USER'S INSTRUCTIONS:
${t.replace("{extracted_text}",g).replace("{user_name}",o)}

CRITICAL REALISM RULES:
1. LENGTH: 15-30 words. Real people are busy.
2. TONE: Match their energy. If they write 5 words, you write 7-10.
3. NATURAL: Use contractions (I'm, we're, that's). Be conversational.
4. QUESTIONS: Max ONE follow-up question.
5. AVOID AI PATTERNS:
   - "Thank you for reaching out"
   - "I hope this finds you well"
   - "I'd be happy to..."
   - Corporate jargon
   - Over-enthusiasm (!!!)

Respond as ${s}. Type like you're between meetings.`,N=r?"https://api.groq.com/openai/v1/chat/completions":"https://api.openai.com/v1/chat/completions",I=r?c:"gpt-4o-mini";let k=150;r&&(c==="openai/gpt-oss-120b"?k=500:k=250);const R=await fetch(N,{method:"POST",headers:{Authorization:`Bearer ${e}`,"Content-Type":"application/json"},body:JSON.stringify({model:I,messages:[{role:"system",content:O},...m.map(x=>({role:x.type==="received"?"user":"assistant",content:x.content}))],max_tokens:k,temperature:.7})});if(!R.ok)throw new Error(`${r?"Groq":"OpenAI"} API Error`);const u=await R.json(),d=(((D=u.usage)==null?void 0:D.prompt_tokens)||0)+(((l=u.usage)==null?void 0:l.completion_tokens)||0);return{reply:u.choices[0].message.content.trim(),tokensUsed:d}}function Ve(){var t;const e=document.querySelector(".global-nav__me-content span");return((t=e==null?void 0:e.textContent)==null?void 0:t.trim())||"You"}function se(e){return{"openai/gpt-oss-120b":"GPT-OSS-120B","llama-3.3-70b-versatile":"Llama-3.3-70B","meta-llama/llama-4-scout-17b-16e-instruct":"Llama-4-Scout","meta-llama/llama-4-maverick-17b-128e-instruct":"Llama-4-Maverick","moonshotai/kimi-k2-instruct-0905":"Kimi-K2","qwen/qwen3-32b":"Qwen-3-32B","gpt-4o-mini":"GPT-4o-mini","gpt-4o":"GPT-4o"}[e]||e}function Qe(e,t){var o,s;const n=[e.toLowerCase(),((o=t==null?void 0:t.company)==null?void 0:o.toLowerCase())||"",((s=t==null?void 0:t.jobTitle)==null?void 0:s.toLowerCase())||""];for(const a of te){const r=a.toLowerCase();for(const c of n)if(c&&c.includes(r))return!0}return!1}async function Xe(e,t){return new Promise(n=>{v=n,chrome.storage.local.set({pendingReply:{leadName:e,reply:t,timestamp:Date.now()}}),i("INFO",`Waiting for approval to reply to ${e}...`,"System"),setTimeout(()=>{v&&(i("WARNING",`Reply approval timed out for ${e}`,"System"),v({approved:!1,reply:""}),v=null,chrome.storage.local.remove(["pendingReply"]))},5*60*1e3)})}async function ae(e){var I,k;i("INFO",`Starting batch of ${e} chats...`,"System");const{apiKey:t,groqApiKey:n,chatMin:o,chatMax:s,loopMin:a,loopMax:r,prompt:c,leadPrompt:m,targetEmail:g,startHour:S,endHour:T}=await He(),A=K?n:t,C=K?Z:"gpt-4o-mini";if(L("currentModel",se(C)),te=(await chrome.storage.local.get(["blacklist"])).blacklist||[],X&&!Fe(S,T)){i("WARNING",`Outside working hours (${S}-${T}). Pausing.`,"System"),b&&!M&&(W=window.setTimeout(()=>ae(e),15*60*1e3));return}const O=Ve();await Be(5);let N=Array.from(document.querySelectorAll("ul.msg-conversations-container__conversations-list li")).slice(0,e).sort(()=>Math.random()-.2);i("INFO",`Found ${N.length} conversations to check.`,"Bot");for(let R=0;R<N.length&&b;R++){for(;M&&b;)await p(1e3);if(!b)break;await je(),await me(o,s);const u=N[R].querySelector("a, .msg-conversation-listitem__link, [tabindex='0']");u==null||u.click(),await p(2e3);const d=qe();if(!d)continue;const D=Ge(d);if(!D||!D.fromLead){i("INFO",`Skipping ${d}: Last message was from me.`,"Bot");continue}const l=await ze(d);if(Qe(d,l.profile)){i("WARNING",`Skipping ${d}: Blacklisted`,"Bot");continue}if(i("INFO",`Checking chat with ${B(d,l.profile)}...`,"Bot"),L("chatsProcessed",1),l.messages.length===0){i("WARNING",`No messages found for ${d}`,"System");continue}const x=l.messages.slice(-8).map(h=>({speaker:h.speaker,message:h.content}));let _;try{_=await ge(A,x,d),i("ACTION",`AI Decision for ${d}: ${_.shouldReply?"REPLY":"SKIP"} (${_.reason})`,"Bot")}catch(h){i("ERROR",`AI Decision Failed: ${re(h)}`,"System");continue}if(!_.shouldReply)continue;if(g)try{const h=l.messages.slice(-2).map(f=>f.content);if(await he(A,m,h)){const f=l.messages.map($=>`${$.speaker}: ${$.content}`).join(`
`);await ye(d,f,g),L("leadsFound",1),i("SUCCESS",`HOT LEAD FOUND: ${d}. Email sent!`,"Bot")}}catch(h){i("ERROR",`Lead check failed: ${re(h)}`,"System")}let z;try{z=await Je(A,c,l.messages,d,O,l.profile,K,Z),L("tokensUsed",z.tokensUsed)}catch(h){i("ERROR",`Reply Generation Failed: ${re(h)}`,"System");continue}let U=z.reply;if(ee){const h=await Xe(d,z.reply);if(!h.approved){i("INFO",`Reply to ${d} was skipped by user`,"User");continue}U=h.reply}const G=document.querySelector("div.msg-form__contenteditable[role='textbox']"),E=document.querySelector("button.msg-form__send-button");if(G&&E){const h={messageCount:l.messages.length,lastMessageQuestions:(((I=l.messages[l.messages.length-1])==null?void 0:I.content.match(/\?/g))||[]).length},f=Ee(U,h)?Ce(U,h):null;if(f){i("ACTION",`Double-texting ${d} (${f.pattern})...`,"Bot");const $=ne(f.firstMessage);if(await p($),await oe(G,f.firstMessage),await p(800),!(E.hasAttribute("disabled")||E.classList.contains("disabled"))){E.click(),await p(500);const J=$e(f.pattern);i("INFO",`Waiting ${Math.round(J/1e3)}s before second message...`,"Bot"),await p(J);const tt=ne(f.secondMessage);await p(tt),await oe(G,f.secondMessage),await p(800),E.hasAttribute("disabled")||E.classList.contains("disabled")||(E.click(),await p(500),L("repliesSent",1),l.messages.push({speaker:O,content:f.firstMessage,timestamp:Date.now()-J,type:"sent"},{speaker:O,content:f.secondMessage,timestamp:Date.now(),type:"sent"}),l.metadata.lastActivity=Date.now(),l.metadata.lastMessageFrom="me",l.metadata.totalMessages+=2,l.metadata.lastSyncedAt=Date.now(),await Q(l),i("SUCCESS",`Double-texted ${B(d,l.profile)} (${se(C)}) [History: ${l.messages.length} msgs]`,"Bot"))}}else{const $=ne(U);i("ACTION",`Typing reply to ${d} (waiting ${Math.round($/1e3)}s)...`,"Bot"),await p($),await oe(G,U),await p(800),E.hasAttribute("disabled")||E.classList.contains("disabled")?i("ERROR",`Send button disabled for ${d}`,"System"):(E.click(),await p(500),(((k=G.textContent)==null?void 0:k.trim())||"").length===0?(L("repliesSent",1),l.messages.push({speaker:O,content:U,timestamp:Date.now(),type:"sent"}),l.metadata.lastActivity=Date.now(),l.metadata.lastMessageFrom="me",l.metadata.totalMessages++,l.metadata.lastSyncedAt=Date.now(),await Q(l),i("SUCCESS",`Sent reply to ${B(d,l.profile)} (${se(C)}) [History: ${l.messages.length} msgs]`,"Bot")):i("WARNING",`Message may not have sent to ${d}`,"System"))}}else i("ERROR","Could not find chat input box","System");await me(o,s)}i("INFO","Batch finished. Sleeping...","System"),b&&!M&&(W=window.setTimeout(()=>ae(e),Math.floor(Math.random()*(r-a+1))+a))}function me(e,t){return p(Math.floor(Math.random()*(t-e+1))+e)}function re(e){return typeof e=="string"?e:e&&typeof e=="object"&&"message"in e?e.message:"Unknown error"}chrome.runtime.onMessage.addListener((e,t,n)=>{var o,s,a,r,c,m;if(e.type==="PING_TEST"){n("‚úÖ Content script active!");return}if(e.type==="GET_STATUS"){n({running:b,paused:M,stats:H,logs:q});return}if(e.type==="START_BOT"){b?n({status:"error",error:"Already running"}):(b=!0,M=!1,H={chatsProcessed:0,repliesSent:0,leadsFound:0,startTime:Date.now(),tokensUsed:0,currentModel:""},X=((o=e.config)==null?void 0:o.strictHours)??!0,K=((s=e.config)==null?void 0:s.useGroq)??!1,Z=((a=e.config)==null?void 0:a.groqModel)??"llama-3.3-70b-versatile",ee=((r=e.config)==null?void 0:r.replyPreviewEnabled)??!1,te=((c=e.config)==null?void 0:c.blacklist)??[],i("INFO",`Bot started (Provider: ${K?"Groq":"OpenAI"}, Strict Hours: ${X?"ON":"OFF"}, Preview: ${ee?"ON":"OFF"})`,"User"),ae(((m=e.config)==null?void 0:m.nChats)??10),n({status:"ok"}));return}if(e.type==="STOP_BOT"){b=!1,M=!1,W!==null&&clearTimeout(W),i("INFO","Bot stopped by user","User"),n({status:"stopped"});return}if(e.type==="PAUSE_BOT"){b&&!M?(M=!0,i("INFO","Bot paused by user","User"),n({status:"paused"})):n({status:"error",error:"Not running or already paused"});return}if(e.type==="RESUME_BOT"){b&&M?(M=!1,i("INFO","Bot resumed by user","User"),n({status:"running"})):n({status:"error",error:"Not paused"});return}if(e.type==="APPROVE_REPLY"){v&&(i("SUCCESS",`Reply to ${e.leadName} approved`,"User"),v({approved:!0,reply:e.reply}),v=null,chrome.storage.local.remove(["pendingReply"])),n({status:"ok"});return}if(e.type==="REJECT_REPLY"){v&&(i("INFO",`Reply to ${e.leadName} rejected`,"User"),v({approved:!1,reply:""}),v=null,chrome.storage.local.remove(["pendingReply"])),n({status:"ok"});return}if(e.type==="CHECK_UNREAD"){b&&!M&&i("INFO","Check unread triggered by background","System"),n({status:"ok"});return}})})();
